{
    "api.supers.time_createadd": {
        "code": "class supers:\n    def time_createadd(self, tarfile_path):\n        assert self.ds.create('newsubds')\n\n    def setup(self, tarfile_path):\n        import tarfile\n        tempdir = osp.dirname(tarfile_path)\n        with tarfile.open(tarfile_path) as tar:\n            tar.extractall(tempdir)\n    \n        # TODO -- remove this abomination after https://github.com/datalad/datalad/issues/1512 is fixed\n        epath = opj(tempdir, 'testds1')\n        epath_unique = epath + str(self.__class__.ds_count)\n        os.rename(epath, epath_unique)\n        self.__class__.ds_count += 1\n        self.ds = Dataset(epath_unique)\n        print(\"Finished setup for %s\" % tempdir)\n\n    def setup_cache(self):\n        # creating in CWD so things get removed when ASV is done\n        ds_path = create_test_dataset(\"testds1\", spec='2/-2/-2', seed=0)[0]\n        # Will store into a tarfile since otherwise install -r is way too slow\n        # to be invoked for every benchmark\n        tarfile_path = opj(osp.dirname(ds_path), 'testds1.tar')\n        with tarfile.open(tarfile_path, \"w\") as tar:\n            # F.CK -- Python tarfile can't later extract those because key dirs are\n            # read-only.  For now just a workaround - make it all writeable\n            from datalad.utils import rotree\n            rotree('testds1', ro=False, chmod_files=False)\n            tar.add('testds1', recursive=True)\n        rmtree('testds1')\n    \n        return tarfile_path", 
        "min_run_count": 2, 
        "name": "api.supers.time_createadd", 
        "number": 0, 
        "param_names": [], 
        "params": [], 
        "processes": 2, 
        "repeat": 0, 
        "sample_time": 0.01, 
        "setup_cache_key": "/home/yoh/proj/datalad/datalad/benchmarks/api.py:64", 
        "timeout": 3600, 
        "type": "time", 
        "unit": "seconds", 
        "version": "9627ffa29956a92e4610615ede7b621bbe831df9d5aaf99d228a681b49a65b1f", 
        "warmup_time": -1
    }, 
    "api.supers.time_createadd_to_dataset": {
        "code": "class supers:\n    def time_createadd_to_dataset(self, tarfile_path):\n        subds = create(opj(self.ds.path, 'newsubds'))\n        self.ds.add(subds.path)\n\n    def setup(self, tarfile_path):\n        import tarfile\n        tempdir = osp.dirname(tarfile_path)\n        with tarfile.open(tarfile_path) as tar:\n            tar.extractall(tempdir)\n    \n        # TODO -- remove this abomination after https://github.com/datalad/datalad/issues/1512 is fixed\n        epath = opj(tempdir, 'testds1')\n        epath_unique = epath + str(self.__class__.ds_count)\n        os.rename(epath, epath_unique)\n        self.__class__.ds_count += 1\n        self.ds = Dataset(epath_unique)\n        print(\"Finished setup for %s\" % tempdir)\n\n    def setup_cache(self):\n        # creating in CWD so things get removed when ASV is done\n        ds_path = create_test_dataset(\"testds1\", spec='2/-2/-2', seed=0)[0]\n        # Will store into a tarfile since otherwise install -r is way too slow\n        # to be invoked for every benchmark\n        tarfile_path = opj(osp.dirname(ds_path), 'testds1.tar')\n        with tarfile.open(tarfile_path, \"w\") as tar:\n            # F.CK -- Python tarfile can't later extract those because key dirs are\n            # read-only.  For now just a workaround - make it all writeable\n            from datalad.utils import rotree\n            rotree('testds1', ro=False, chmod_files=False)\n            tar.add('testds1', recursive=True)\n        rmtree('testds1')\n    \n        return tarfile_path", 
        "min_run_count": 2, 
        "name": "api.supers.time_createadd_to_dataset", 
        "number": 0, 
        "param_names": [], 
        "params": [], 
        "processes": 2, 
        "repeat": 0, 
        "sample_time": 0.01, 
        "setup_cache_key": "/home/yoh/proj/datalad/datalad/benchmarks/api.py:64", 
        "timeout": 3600, 
        "type": "time", 
        "unit": "seconds", 
        "version": "994ddd7edd278a30db53653e54e9976a39e1bde83b663d095e76217d683e1992", 
        "warmup_time": -1
    }, 
    "api.supers.time_installr": {
        "code": "class supers:\n    def time_installr(self, tarfile_path):\n        # somewhat duplicating setup but lazy to do different one for now\n        assert install(self.ds.path + '_', source=self.ds.path, recursive=True)\n\n    def setup(self, tarfile_path):\n        import tarfile\n        tempdir = osp.dirname(tarfile_path)\n        with tarfile.open(tarfile_path) as tar:\n            tar.extractall(tempdir)\n    \n        # TODO -- remove this abomination after https://github.com/datalad/datalad/issues/1512 is fixed\n        epath = opj(tempdir, 'testds1')\n        epath_unique = epath + str(self.__class__.ds_count)\n        os.rename(epath, epath_unique)\n        self.__class__.ds_count += 1\n        self.ds = Dataset(epath_unique)\n        print(\"Finished setup for %s\" % tempdir)\n\n    def setup_cache(self):\n        # creating in CWD so things get removed when ASV is done\n        ds_path = create_test_dataset(\"testds1\", spec='2/-2/-2', seed=0)[0]\n        # Will store into a tarfile since otherwise install -r is way too slow\n        # to be invoked for every benchmark\n        tarfile_path = opj(osp.dirname(ds_path), 'testds1.tar')\n        with tarfile.open(tarfile_path, \"w\") as tar:\n            # F.CK -- Python tarfile can't later extract those because key dirs are\n            # read-only.  For now just a workaround - make it all writeable\n            from datalad.utils import rotree\n            rotree('testds1', ro=False, chmod_files=False)\n            tar.add('testds1', recursive=True)\n        rmtree('testds1')\n    \n        return tarfile_path", 
        "min_run_count": 2, 
        "name": "api.supers.time_installr", 
        "number": 0, 
        "param_names": [], 
        "params": [], 
        "processes": 2, 
        "repeat": 0, 
        "sample_time": 0.01, 
        "setup_cache_key": "/home/yoh/proj/datalad/datalad/benchmarks/api.py:64", 
        "timeout": 3600, 
        "type": "time", 
        "unit": "seconds", 
        "version": "f9cd0ceef63e4692e520a08a0d61942b9f08151fbe0ff38bc562aab505e7d204", 
        "warmup_time": -1
    }, 
    "api.supers.time_ls": {
        "code": "class supers:\n    def time_ls(self, tarfile_path):\n        ls(self.ds.path)\n\n    def setup(self, tarfile_path):\n        import tarfile\n        tempdir = osp.dirname(tarfile_path)\n        with tarfile.open(tarfile_path) as tar:\n            tar.extractall(tempdir)\n    \n        # TODO -- remove this abomination after https://github.com/datalad/datalad/issues/1512 is fixed\n        epath = opj(tempdir, 'testds1')\n        epath_unique = epath + str(self.__class__.ds_count)\n        os.rename(epath, epath_unique)\n        self.__class__.ds_count += 1\n        self.ds = Dataset(epath_unique)\n        print(\"Finished setup for %s\" % tempdir)\n\n    def setup_cache(self):\n        # creating in CWD so things get removed when ASV is done\n        ds_path = create_test_dataset(\"testds1\", spec='2/-2/-2', seed=0)[0]\n        # Will store into a tarfile since otherwise install -r is way too slow\n        # to be invoked for every benchmark\n        tarfile_path = opj(osp.dirname(ds_path), 'testds1.tar')\n        with tarfile.open(tarfile_path, \"w\") as tar:\n            # F.CK -- Python tarfile can't later extract those because key dirs are\n            # read-only.  For now just a workaround - make it all writeable\n            from datalad.utils import rotree\n            rotree('testds1', ro=False, chmod_files=False)\n            tar.add('testds1', recursive=True)\n        rmtree('testds1')\n    \n        return tarfile_path", 
        "min_run_count": 2, 
        "name": "api.supers.time_ls", 
        "number": 0, 
        "param_names": [], 
        "params": [], 
        "processes": 2, 
        "repeat": 0, 
        "sample_time": 0.01, 
        "setup_cache_key": "/home/yoh/proj/datalad/datalad/benchmarks/api.py:64", 
        "timeout": 3600, 
        "type": "time", 
        "unit": "seconds", 
        "version": "090ffbfc5ed895f49055534c197753baacb35f8bb3c1a69013c1011738ca300f", 
        "warmup_time": -1
    }, 
    "api.supers.time_ls_recursive": {
        "code": "class supers:\n    def time_ls_recursive(self, tarfile_path):\n        ls(self.ds.path, recursive=True)\n\n    def setup(self, tarfile_path):\n        import tarfile\n        tempdir = osp.dirname(tarfile_path)\n        with tarfile.open(tarfile_path) as tar:\n            tar.extractall(tempdir)\n    \n        # TODO -- remove this abomination after https://github.com/datalad/datalad/issues/1512 is fixed\n        epath = opj(tempdir, 'testds1')\n        epath_unique = epath + str(self.__class__.ds_count)\n        os.rename(epath, epath_unique)\n        self.__class__.ds_count += 1\n        self.ds = Dataset(epath_unique)\n        print(\"Finished setup for %s\" % tempdir)\n\n    def setup_cache(self):\n        # creating in CWD so things get removed when ASV is done\n        ds_path = create_test_dataset(\"testds1\", spec='2/-2/-2', seed=0)[0]\n        # Will store into a tarfile since otherwise install -r is way too slow\n        # to be invoked for every benchmark\n        tarfile_path = opj(osp.dirname(ds_path), 'testds1.tar')\n        with tarfile.open(tarfile_path, \"w\") as tar:\n            # F.CK -- Python tarfile can't later extract those because key dirs are\n            # read-only.  For now just a workaround - make it all writeable\n            from datalad.utils import rotree\n            rotree('testds1', ro=False, chmod_files=False)\n            tar.add('testds1', recursive=True)\n        rmtree('testds1')\n    \n        return tarfile_path", 
        "min_run_count": 2, 
        "name": "api.supers.time_ls_recursive", 
        "number": 0, 
        "param_names": [], 
        "params": [], 
        "processes": 2, 
        "repeat": 0, 
        "sample_time": 0.01, 
        "setup_cache_key": "/home/yoh/proj/datalad/datalad/benchmarks/api.py:64", 
        "timeout": 3600, 
        "type": "time", 
        "unit": "seconds", 
        "version": "d02744c6b0c50fb150b7e596ca541160f70a4933daac66d3b78b7ccdd6fc6c2f", 
        "warmup_time": -1
    }, 
    "api.supers.time_ls_recursive_long_all": {
        "code": "class supers:\n    def time_ls_recursive_long_all(self, tarfile_path):\n        ls(self.ds.path, recursive=True, long_=True, all_=True)\n\n    def setup(self, tarfile_path):\n        import tarfile\n        tempdir = osp.dirname(tarfile_path)\n        with tarfile.open(tarfile_path) as tar:\n            tar.extractall(tempdir)\n    \n        # TODO -- remove this abomination after https://github.com/datalad/datalad/issues/1512 is fixed\n        epath = opj(tempdir, 'testds1')\n        epath_unique = epath + str(self.__class__.ds_count)\n        os.rename(epath, epath_unique)\n        self.__class__.ds_count += 1\n        self.ds = Dataset(epath_unique)\n        print(\"Finished setup for %s\" % tempdir)\n\n    def setup_cache(self):\n        # creating in CWD so things get removed when ASV is done\n        ds_path = create_test_dataset(\"testds1\", spec='2/-2/-2', seed=0)[0]\n        # Will store into a tarfile since otherwise install -r is way too slow\n        # to be invoked for every benchmark\n        tarfile_path = opj(osp.dirname(ds_path), 'testds1.tar')\n        with tarfile.open(tarfile_path, \"w\") as tar:\n            # F.CK -- Python tarfile can't later extract those because key dirs are\n            # read-only.  For now just a workaround - make it all writeable\n            from datalad.utils import rotree\n            rotree('testds1', ro=False, chmod_files=False)\n            tar.add('testds1', recursive=True)\n        rmtree('testds1')\n    \n        return tarfile_path", 
        "min_run_count": 2, 
        "name": "api.supers.time_ls_recursive_long_all", 
        "number": 0, 
        "param_names": [], 
        "params": [], 
        "processes": 2, 
        "repeat": 0, 
        "sample_time": 0.01, 
        "setup_cache_key": "/home/yoh/proj/datalad/datalad/benchmarks/api.py:64", 
        "timeout": 3600, 
        "type": "time", 
        "unit": "seconds", 
        "version": "b87eb69e3352d67e40bc22b3f54e9be3b4f11eeb821186da240031e4953764b9", 
        "warmup_time": -1
    }, 
    "api.supers.time_remove": {
        "code": "class supers:\n    def time_remove(self, tarfile_path):\n        remove(self.ds.path, recursive=True)\n\n    def setup(self, tarfile_path):\n        import tarfile\n        tempdir = osp.dirname(tarfile_path)\n        with tarfile.open(tarfile_path) as tar:\n            tar.extractall(tempdir)\n    \n        # TODO -- remove this abomination after https://github.com/datalad/datalad/issues/1512 is fixed\n        epath = opj(tempdir, 'testds1')\n        epath_unique = epath + str(self.__class__.ds_count)\n        os.rename(epath, epath_unique)\n        self.__class__.ds_count += 1\n        self.ds = Dataset(epath_unique)\n        print(\"Finished setup for %s\" % tempdir)\n\n    def setup_cache(self):\n        # creating in CWD so things get removed when ASV is done\n        ds_path = create_test_dataset(\"testds1\", spec='2/-2/-2', seed=0)[0]\n        # Will store into a tarfile since otherwise install -r is way too slow\n        # to be invoked for every benchmark\n        tarfile_path = opj(osp.dirname(ds_path), 'testds1.tar')\n        with tarfile.open(tarfile_path, \"w\") as tar:\n            # F.CK -- Python tarfile can't later extract those because key dirs are\n            # read-only.  For now just a workaround - make it all writeable\n            from datalad.utils import rotree\n            rotree('testds1', ro=False, chmod_files=False)\n            tar.add('testds1', recursive=True)\n        rmtree('testds1')\n    \n        return tarfile_path", 
        "min_run_count": 2, 
        "name": "api.supers.time_remove", 
        "number": 0, 
        "param_names": [], 
        "params": [], 
        "processes": 2, 
        "repeat": 0, 
        "sample_time": 0.01, 
        "setup_cache_key": "/home/yoh/proj/datalad/datalad/benchmarks/api.py:64", 
        "timeout": 3600, 
        "type": "time", 
        "unit": "seconds", 
        "version": "d90e236129ab9910e61fb2ce6efa667543c915f46b937ef5187a0658369b4fa0", 
        "warmup_time": -1
    }, 
    "api.testds.time_create_test_dataset1": {
        "code": "class testds:\n    def time_create_test_dataset1(self):\n        create_test_dataset(spec='1', seed=0)", 
        "min_run_count": 2, 
        "name": "api.testds.time_create_test_dataset1", 
        "number": 0, 
        "param_names": [], 
        "params": [], 
        "processes": 2, 
        "repeat": 0, 
        "sample_time": 0.01, 
        "timeout": 60.0, 
        "type": "time", 
        "unit": "seconds", 
        "version": "9ecd497c5dd148ef03187ff8e66872e3a1ae97083bbf12e726b9fadfc6358f8e", 
        "warmup_time": -1
    }, 
    "api.testds.time_create_test_dataset2x2": {
        "code": "class testds:\n    def time_create_test_dataset2x2(self):\n        create_test_dataset(spec='2/2', seed=0)", 
        "min_run_count": 2, 
        "name": "api.testds.time_create_test_dataset2x2", 
        "number": 0, 
        "param_names": [], 
        "params": [], 
        "processes": 2, 
        "repeat": 0, 
        "sample_time": 0.01, 
        "timeout": 60.0, 
        "type": "time", 
        "unit": "seconds", 
        "version": "fca09bf52102f408d7d0a57e79ddbbb329eda25dffaf38c863f3271f7b7547c0", 
        "warmup_time": -1
    }, 
    "core.runner.time_echo": {
        "code": "class runner:\n    def time_echo(self):\n        self.runner.run(\"echo\")\n\n    def setup(self):\n        from datalad.cmd import Runner\n        self.runner = Runner()\n        # older versions might not have it\n        try:\n            from datalad.cmd import GitRunner\n            self.git_runner = GitRunner()\n        except ImportError:\n            pass", 
        "min_run_count": 2, 
        "name": "core.runner.time_echo", 
        "number": 0, 
        "param_names": [], 
        "params": [], 
        "processes": 2, 
        "repeat": 0, 
        "sample_time": 0.01, 
        "timeout": 60.0, 
        "type": "time", 
        "unit": "seconds", 
        "version": "fa3e886cf31276383138dcece3a41704add08700c4c756bcd65830edd5f87764", 
        "warmup_time": -1
    }, 
    "core.runner.time_echo_gitrunner": {
        "code": "class runner:\n    def time_echo_gitrunner(self):\n        self.git_runner.run(\"echo\")\n\n    def setup(self):\n        from datalad.cmd import Runner\n        self.runner = Runner()\n        # older versions might not have it\n        try:\n            from datalad.cmd import GitRunner\n            self.git_runner = GitRunner()\n        except ImportError:\n            pass", 
        "min_run_count": 2, 
        "name": "core.runner.time_echo_gitrunner", 
        "number": 0, 
        "param_names": [], 
        "params": [], 
        "processes": 2, 
        "repeat": 0, 
        "sample_time": 0.01, 
        "timeout": 60.0, 
        "type": "time", 
        "unit": "seconds", 
        "version": "e128fce0653554d3d8f58f8b55c32414bb826b3ca7350b43cbf171ce3e6f6e32", 
        "warmup_time": -1
    }, 
    "core.startup.time_help_np": {
        "code": "class startup:\n    def time_help_np(self):\n        call([\"datalad\", \"--help-np\"], env=self.env)\n\n    def setup(self):\n        # we need to prepare/adjust PATH to point to installed datalad\n        # We will base it on taking sys.executable\n        python_path = osp.dirname(sys.executable)\n        self.env = os.environ.copy()\n        self.env['PATH'] = '%s:%s' % (python_path, self.env.get('PATH', ''))", 
        "min_run_count": 2, 
        "name": "core.startup.time_help_np", 
        "number": 0, 
        "param_names": [], 
        "params": [], 
        "processes": 2, 
        "repeat": 0, 
        "sample_time": 0.01, 
        "timeout": 60.0, 
        "type": "time", 
        "unit": "seconds", 
        "version": "78c62df8b90b52ee22470b016afc051ef28ea2b4598ecaf3337d7c1d8a142479", 
        "warmup_time": -1
    }, 
    "core.startup.time_import": {
        "code": "class startup:\n    def time_import(self):\n        call([sys.executable, \"-c\", \"import datalad\"])\n\n    def setup(self):\n        # we need to prepare/adjust PATH to point to installed datalad\n        # We will base it on taking sys.executable\n        python_path = osp.dirname(sys.executable)\n        self.env = os.environ.copy()\n        self.env['PATH'] = '%s:%s' % (python_path, self.env.get('PATH', ''))", 
        "min_run_count": 2, 
        "name": "core.startup.time_import", 
        "number": 0, 
        "param_names": [], 
        "params": [], 
        "processes": 2, 
        "repeat": 0, 
        "sample_time": 0.01, 
        "timeout": 60.0, 
        "type": "time", 
        "unit": "seconds", 
        "version": "5a62b417a0fe0b72410c5ac3b48be93ecac330c06565763b0209e5d0fedcc05e", 
        "warmup_time": -1
    }, 
    "core.startup.time_import_api": {
        "code": "class startup:\n    def time_import_api(self):\n        call([sys.executable, \"-c\", \"import datalad.api\"])\n\n    def setup(self):\n        # we need to prepare/adjust PATH to point to installed datalad\n        # We will base it on taking sys.executable\n        python_path = osp.dirname(sys.executable)\n        self.env = os.environ.copy()\n        self.env['PATH'] = '%s:%s' % (python_path, self.env.get('PATH', ''))", 
        "min_run_count": 2, 
        "name": "core.startup.time_import_api", 
        "number": 0, 
        "param_names": [], 
        "params": [], 
        "processes": 2, 
        "repeat": 0, 
        "sample_time": 0.01, 
        "timeout": 60.0, 
        "type": "time", 
        "unit": "seconds", 
        "version": "ad7803b5cd3d3e2b45adbdbf8df9b4a3d483d0da621644a9476182740cb46246", 
        "warmup_time": -1
    }, 
    "version": 2
}